{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "pLhBuqz8AhR9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhllqKQThOVA"
      },
      "source": [
        "Code based on: https://github.com/atong01/conditional-flow-matching/tree/main\n",
        "\n",
        "\n",
        "## Required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEYfPi4zhUn3"
      },
      "outputs": [],
      "source": [
        "!pip install torchdyn;\n",
        "!pip install torchcfm;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG86hshHhft9"
      },
      "source": [
        "## Importing Libaries and initiating device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e9iEwi_hput8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e314f1b-7a8c-434b-ad9a-1d9e3a05729e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ot/backend.py:2998: UserWarning: To use TensorflowBackend, you need to activate the tensorflow numpy API. You can activate it by running: \n",
            "from tensorflow.python.ops.numpy_ops import np_config\n",
            "np_config.enable_numpy_behavior()\n",
            "  register_backend(TensorflowBackend())\n"
          ]
        }
      ],
      "source": [
        "# Libs:\n",
        "import copy\n",
        "import os\n",
        "import math\n",
        "\n",
        "from tqdm import trange\n",
        "from absl import app, flags\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchdyn.core import NeuralODE\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "from torchcfm.conditional_flow_matching import ( ConditionalFlowMatcher, ExactOptimalTransportConditionalFlowMatcher, VariancePreservingConditionalFlowMatcher,)\n",
        "from torchcfm.models.unet.unet import UNetModelWrapper\n",
        "\n",
        "# Device initiation:\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x8IkUT7kX_U"
      },
      "source": [
        "## Help functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_samples(model, parallel, savedir, step, net_=\"normal\"):\n",
        "    \"\"\"Save 64 generated images (8 x 8) for sanity check along training.\n",
        "    Parameters\n",
        "    ----------\n",
        "    model:\n",
        "        represents the neural network that we want to generate samples from\n",
        "    parallel: bool\n",
        "        represents the parallel training flag. Torchdyn only runs on 1 GPU, we need to send the models from several GPUs to 1 GPU.\n",
        "    savedir: str\n",
        "        represents the path where we want to save the generated images\n",
        "    step: int\n",
        "        represents the current step of training\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    model_ = copy.deepcopy(model)\n",
        "    if parallel:\n",
        "        # Send the models from GPU to CPU for inference with NeuralODE from Torchdyn\n",
        "        model_ = model_.module.to(device)\n",
        "\n",
        "    node_ = NeuralODE(model_, solver=\"euler\", sensitivity=\"adjoint\")\n",
        "    with torch.no_grad():\n",
        "        traj = node_.trajectory(\n",
        "            torch.randn(64, 3, 32, 32).to(device),\n",
        "            t_span=torch.linspace(0, 1, 100).to(device),\n",
        "        )\n",
        "        traj = traj[-1, :].view([-1, 3, 32, 32]).clip(-1, 1)\n",
        "        traj = traj / 2 + 0.5\n",
        "    save_image(traj, savedir + f\"{net_}_generated_FM_images_step_{step}.png\", nrow=8)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def ema(source, target, decay):\n",
        "    source_dict = source.state_dict()\n",
        "    target_dict = target.state_dict()\n",
        "    for key in source_dict.keys():\n",
        "        target_dict[key].data.copy_(\n",
        "            target_dict[key].data * decay + source_dict[key].data * (1 - decay)\n",
        "        )\n",
        "\n",
        "def infiniteloop(dataloader):\n",
        "    while True:\n",
        "        for x, y in iter(dataloader):\n",
        "            yield x\n",
        "\n",
        "def warmup_lr(step):\n",
        "    return min(step, warmup) / warmup"
      ],
      "metadata": {
        "id": "EbNgCKOpwqd2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dPyBXSVrp1ck"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "model_name = \"otcfm\" # Flow matching model type, otcfm or vpcfm\n",
        "output_dir = \"./results/\" # Output_directory\n",
        "\n",
        "# UNet\n",
        "num_channel = 64 # Base channel of UNet\n",
        "\n",
        "# Training\n",
        "lr = 2e-4 # Target learning rate\n",
        "grad_clip = 1.0 # Gradient norm clipping\n",
        "total_steps = 400000 # Total training steps, Lipman et al uses 400k and double batch size, we used: 40k and batch size: 64\n",
        "warmup = 1000 # Learning rate warmup\n",
        "batch_size = 32 # batch size, Lipman et al uses 128\n",
        "num_workers = 4 # Workers of Dataloader\n",
        "ema_decay = 0.9999 # Ema decay rate\n",
        "parallel = False # Multi gpu training\n",
        "\n",
        "# Evaluation\n",
        "save_step = 100 # Frequency of saving checkpoints, 0 to disable during training\"\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "bEkieQWsG18i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p8AlCVPEpsEo"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    eval_loss = []\n",
        "    print(\n",
        "        \"lr, total_steps, ema decay, save_step:\",\n",
        "        lr,\n",
        "        total_steps,\n",
        "        ema_decay,\n",
        "        save_step,\n",
        "    )\n",
        "    print(warmup_lr)\n",
        "\n",
        "    # DATASETS\n",
        "    dataset = datasets.CIFAR10(\n",
        "        root=\"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [   transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ]   ),\n",
        "    )\n",
        "    # DATALOADER\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        drop_last=True,\n",
        "    )\n",
        "\n",
        "    datalooper = infiniteloop(dataloader)\n",
        "\n",
        "    # UNET MODEL\n",
        "    net_model = UNetModelWrapper(\n",
        "        dim=(3, 32, 32),\n",
        "        num_res_blocks=2,\n",
        "        num_channels=num_channel,\n",
        "        channel_mult=[1, 2, 2, 2],\n",
        "        num_heads=4,\n",
        "        num_head_channels=64,\n",
        "        attention_resolutions=\"16\",\n",
        "        dropout=0.1,\n",
        "    ).to( device)\n",
        "    # EMA model\n",
        "    ema_model = copy.deepcopy(net_model)\n",
        "    optim = torch.optim.Adam(net_model.parameters(), lr=lr)\n",
        "    sched = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=warmup_lr)\n",
        "    if parallel:\n",
        "        print(\n",
        "            \"Warning: parallel training is performing slightly worse than single GPU training due to statistics computation in dataparallel. We recommend to train over a single GPU, which requires around 8 Gb of GPU memory.\"\n",
        "        )\n",
        "        net_model = torch.nn.DataParallel(net_model)\n",
        "        ema_model = torch.nn.DataParallel(ema_model)\n",
        "\n",
        "    # Print model size\n",
        "    model_size = 0\n",
        "    for param in net_model.parameters():\n",
        "        model_size += param.data.nelement()\n",
        "    print(\"Model params: %.2f M\" % (model_size / 1024 / 1024))\n",
        "\n",
        "    ######## Choose model ########\n",
        "    sigma = 0.0\n",
        "    if model_name == \"otcfm\":\n",
        "        FM = ExactOptimalTransportConditionalFlowMatcher(sigma=sigma)\n",
        "    elif model_name == \"vpcfm\":\n",
        "        FM = VariancePreservingConditionalFlowMatcher(sigma=sigma)\n",
        "    else:\n",
        "        raise NotImplementedError( f\"Unknown model {model_name}, must be one of ['otcfm','vpcfm']\")\n",
        "\n",
        "    savedir = output_dir + model_name + \"/\"\n",
        "    os.makedirs(savedir, exist_ok=True)\n",
        "\n",
        "    with trange(total_steps, dynamic_ncols=True) as pbar:\n",
        "        for step in pbar:\n",
        "            optim.zero_grad()\n",
        "            x1 = next(datalooper).to(device)\n",
        "            x0 = torch.randn_like(x1)\n",
        "            t, xt, ut = FM.sample_location_and_conditional_flow(x0, x1)\n",
        "            vt = net_model(t, xt)\n",
        "            loss = torch.mean((vt - ut) ** 2)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(net_model.parameters(), grad_clip)\n",
        "            optim.step()\n",
        "            sched.step()\n",
        "            eval_loss.append(loss)\n",
        "            ema(net_model, ema_model, ema_decay)\n",
        "\n",
        "            # Sample and Saving the weights\n",
        "            if save_step > 0 and step % save_step == 0:\n",
        "                print(f', \\Epoch: {step}, Train loss: {loss:.4f}')\n",
        "                generate_samples(net_model, parallel, savedir, step, net_=\"normal\")\n",
        "                generate_samples(ema_model, parallel, savedir, step, net_=\"ema\")\n",
        "                torch.save(\n",
        "                    {\n",
        "                        \"net_model\": net_model.state_dict(),\n",
        "                        \"ema_model\": ema_model.state_dict(),\n",
        "                        \"sched\": sched.state_dict(),\n",
        "                        \"optim\": optim.state_dict(),\n",
        "                        \"step\": step,\n",
        "                    },\n",
        "                    savedir + f\"cifar10_weights_step_{step}.pt\",\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "bSF7EkPvwwrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ed73d9-0ca6-4e96-d505-14076b7264de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr, total_steps, ema decay, save_step: 0.0002 1000 0.9999 100\n",
            "<function warmup_lr at 0x795dc5ee5e10>\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 80376058.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model params: 8.54 M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", \\Epoch: 0, Train loss: 1.2072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCo2TnhXiShk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}